{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-10T20:34:34.345112Z",
     "iopub.status.busy": "2025-11-10T20:34:34.344903Z",
     "iopub.status.idle": "2025-11-10T20:36:11.283878Z",
     "shell.execute_reply": "2025-11-10T20:36:11.282921Z",
     "shell.execute_reply.started": "2025-11-10T20:34:34.345096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.3\n",
      "    Uninstalling transformers-4.53.3:\n",
      "      Successfully uninstalled transformers-4.53.3\n",
      "Successfully installed tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets accelerate evaluate scikit-learn torch\n",
    "!pip install -U transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:11.285886Z",
     "iopub.status.busy": "2025-11-10T20:36:11.285074Z",
     "iopub.status.idle": "2025-11-10T20:36:36.884495Z",
     "shell.execute_reply": "2025-11-10T20:36:36.883860Z",
     "shell.execute_reply.started": "2025-11-10T20:36:11.285853Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 20:36:23.249380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762806983.428166      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762806983.474367      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.886749Z",
     "iopub.status.busy": "2025-11-10T20:36:36.886105Z",
     "iopub.status.idle": "2025-11-10T20:36:36.892194Z",
     "shell.execute_reply": "2025-11-10T20:36:36.891451Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.886729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: float = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: bool = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: bool = True, label_names: Optional[list[str]] = None, load_best_model_at_end: bool = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = None, fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, parallelism_config: Optional[Any] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: str = 'length', report_to: Union[NoneType, str, list[str]] = None, project: str = 'huggingface', trackio_space_id: Optional[str] = 'trackio', ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: bool = False, include_num_input_tokens_seen: Union[str, bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: bool = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: bool = False, average_tokens_across_devices: bool = True) -> None\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from transformers import TrainingArguments\n",
    "print(inspect.signature(TrainingArguments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.893063Z",
     "iopub.status.busy": "2025-11-10T20:36:36.892838Z",
     "iopub.status.idle": "2025-11-10T20:36:36.908299Z",
     "shell.execute_reply": "2025-11-10T20:36:36.907667Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.893047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, random, numpy as np, pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import file and analyze it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.909298Z",
     "iopub.status.busy": "2025-11-10T20:36:36.908924Z",
     "iopub.status.idle": "2025-11-10T20:36:36.922860Z",
     "shell.execute_reply": "2025-11-10T20:36:36.922315Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.909276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Seed=42\n",
    "random.seed(Seed)\n",
    "np.random.seed(Seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(Seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.923836Z",
     "iopub.status.busy": "2025-11-10T20:36:36.923639Z",
     "iopub.status.idle": "2025-11-10T20:36:36.966808Z",
     "shell.execute_reply": "2025-11-10T20:36:36.966256Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.923813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Text', ' Sentiment', ' Source', ' Date/Time', ' User ID', ' Location', ' Confidence Score']\n",
      "                                               Text  Sentiment         Source  \\\n",
      "0                              I love this product!   Positive        Twitter   \n",
      "1                         The service was terrible.   Negative   Yelp Reviews   \n",
      "2                            This movie is amazing!   Positive           IMDb   \n",
      "3  I'm so disappointed with their customer support.   Negative   Online Forum   \n",
      "4                Just had the best meal of my life!   Positive    TripAdvisor   \n",
      "\n",
      "              Date/Time       User ID      Location   Confidence Score  \n",
      "0   2023-06-15 09:23:14      @user123      New York               0.85  \n",
      "1   2023-06-15 11:45:32       user456   Los Angeles               0.65  \n",
      "2   2023-06-15 14:10:22   moviefan789        London               0.92  \n",
      "3   2023-06-15 17:35:11    forumuser1       Toronto               0.78  \n",
      "4   2023-06-16 08:50:59      foodie22         Paris               0.88  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/sensitive-analysis/sentiment-analysis.csv', encoding='utf-8-sig')\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.967784Z",
     "iopub.status.busy": "2025-11-10T20:36:36.967577Z",
     "iopub.status.idle": "2025-11-10T20:36:36.985025Z",
     "shell.execute_reply": "2025-11-10T20:36:36.984282Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.967759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map: {' Negative': 0, ' Positive': 1, 'Negative': 2, 'Positive': 3}\n",
      "                                               Text  Sentiment  label\n",
      "0                              I love this product!   Positive      1\n",
      "1                         The service was terrible.   Negative      0\n",
      "2                            This movie is amazing!   Positive      1\n",
      "3  I'm so disappointed with their customer support.   Negative      0\n",
      "4                Just had the best meal of my life!   Positive      1\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "text_col = 'Text'\n",
    "label_col = 'Sentiment'\n",
    "\n",
    "unique = sorted(df[label_col].unique())\n",
    "label2id = {lab: i for i, lab in enumerate(unique)}\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "\n",
    "df[\"label\"] = df[label_col].map(label2id)\n",
    "\n",
    "print(\"Label map:\", label2id)\n",
    "print(df[[text_col, label_col, \"label\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "### we may observe our sentiments are positive or negative convert them to digit 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets convert our data set into Hugging face format \n",
    "### for testing we are using small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:36.985998Z",
     "iopub.status.busy": "2025-11-10T20:36:36.985716Z",
     "iopub.status.idle": "2025-11-10T20:36:37.007917Z",
     "shell.execute_reply": "2025-11-10T20:36:37.007104Z",
     "shell.execute_reply.started": "2025-11-10T20:36:36.985973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'label'],\n",
      "        num_rows: 364\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Text', 'label'],\n",
      "        num_rows: 92\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data=Dataset.from_pandas(df[[text_col,\"label\"]])\n",
    "data_split=data.train_test_split(test_size=0.2,seed=Seed)\n",
    "dataset=DatasetDict({\"train\":data_split[\"train\"],\"validation\":data_split[\"test\"]})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:37.010311Z",
     "iopub.status.busy": "2025-11-10T20:36:37.010118Z",
     "iopub.status.idle": "2025-11-10T20:36:38.582370Z",
     "shell.execute_reply": "2025-11-10T20:36:38.581566Z",
     "shell.execute_reply.started": "2025-11-10T20:36:37.010296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da20e1b8f824c03804a1601e3c05281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8eb5d2cd6b491d9749835753c32f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb972accf1e4145a69c1548dcbe29cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a311b6ab5f4163afbc962e9221c8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010dd01c20f74595bb52b8caa8772620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ad958216546e2afd07eab0481fe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/92 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_base = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_base)\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[text_col], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:38.583491Z",
     "iopub.status.busy": "2025-11-10T20:36:38.583154Z",
     "iopub.status.idle": "2025-11-10T20:36:40.793157Z",
     "shell.execute_reply": "2025-11-10T20:36:40.792366Z",
     "shell.execute_reply.started": "2025-11-10T20:36:38.583467Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae30eb0d49941548171ef6888dffa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels=len(label2id)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_base,num_labels=num_labels,id2label=id2label,label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:40.794287Z",
     "iopub.status.busy": "2025-11-10T20:36:40.794018Z",
     "iopub.status.idle": "2025-11-10T20:36:40.798436Z",
     "shell.execute_reply": "2025-11-10T20:36:40.797797Z",
     "shell.execute_reply.started": "2025-11-10T20:36:40.794259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaulation metrices\n",
    "from inspect import signature\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:40.799402Z",
     "iopub.status.busy": "2025-11-10T20:36:40.799124Z",
     "iopub.status.idle": "2025-11-10T20:36:41.146790Z",
     "shell.execute_reply": "2025-11-10T20:36:41.146010Z",
     "shell.execute_reply.started": "2025-11-10T20:36:40.799381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39/1921591762.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# hugging face default parameters for model training \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_sentiment\",\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:41.147999Z",
     "iopub.status.busy": "2025-11-10T20:36:41.147638Z",
     "iopub.status.idle": "2025-11-10T20:36:41.152595Z",
     "shell.execute_reply": "2025-11-10T20:36:41.151832Z",
     "shell.execute_reply.started": "2025-11-10T20:36:41.147974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:36:41.153657Z",
     "iopub.status.busy": "2025-11-10T20:36:41.153403Z",
     "iopub.status.idle": "2025-11-10T20:38:13.239327Z",
     "shell.execute_reply": "2025-11-10T20:38:13.238633Z",
     "shell.execute_reply.started": "2025-11-10T20:36:41.153633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 01:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.478617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=460, training_loss=0.1289006680250168, metrics={'train_runtime': 91.6276, 'train_samples_per_second': 39.726, 'train_steps_per_second': 5.02, 'total_flos': 239435359887360.0, 'train_loss': 0.1289006680250168, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:38:13.240792Z",
     "iopub.status.busy": "2025-11-10T20:38:13.240169Z",
     "iopub.status.idle": "2025-11-10T20:38:13.665263Z",
     "shell.execute_reply": "2025-11-10T20:38:13.664460Z",
     "shell.execute_reply.started": "2025-11-10T20:38:13.240771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Macro F1: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00         4\n",
      "    Positive       1.00      1.00      1.00        13\n",
      "    Negative       1.00      1.00      1.00        35\n",
      "    Positive       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           1.00        92\n",
      "   macro avg       1.00      1.00      1.00        92\n",
      "weighted avg       1.00      1.00      1.00        92\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 4  0  0  0]\n",
      " [ 0 13  0  0]\n",
      " [ 0  0 35  0]\n",
      " [ 0  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(dataset[\"validation\"])\n",
    "preds = np.argmax(pred_out.predictions, axis=-1)\n",
    "labels = pred_out.label_ids\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
    "print(\"Macro F1:\", f1_score(labels, preds, average=\"macro\"))\n",
    "label_names = [id2label[i] for i in sorted(set(labels))] \n",
    "print(\"\\nClassification Report:\\n\", classification_report(labels, preds, target_names=label_names))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:38:13.666775Z",
     "iopub.status.busy": "2025-11-10T20:38:13.666239Z",
     "iopub.status.idle": "2025-11-10T20:38:19.591110Z",
     "shell.execute_reply": "2025-11-10T20:38:19.590408Z",
     "shell.execute_reply.started": "2025-11-10T20:38:13.666756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./bert_sentiment/final\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./bert_sentiment/final\")\n",
    "tokenizer.save_pretrained(\"./bert_sentiment/final\")\n",
    "print(\"Saved to ./bert_sentiment/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:38:19.591906Z",
     "iopub.status.busy": "2025-11-10T20:38:19.591725Z",
     "iopub.status.idle": "2025-11-10T20:38:19.679326Z",
     "shell.execute_reply": "2025-11-10T20:38:19.678668Z",
     "shell.execute_reply.started": "2025-11-10T20:38:19.591892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 Text Predicted_Label  Confidence\n",
      "      I thought it would be terrible but it exceeded my expectations!        Negative    0.367108\n",
      "    The product isn't bad but the customer service ruined everything.        Negative    0.393033\n",
      "                      Not the best, not the worst, just okay I guess.        Negative    0.320945\n",
      "          I wanted to love it so badly but it let me down completely.        Negative    0.352130\n",
      "          Despite the flaws, I'm surprisingly happy with my purchase.        Negative    0.348664\n",
      "The reviews said it was amazing but I found it utterly disappointing.        Negative    0.385208\n",
      "    It's fine if you have low expectations, otherwise you'll hate it.        Negative    0.348027\n",
      "         I can't believe how much I regret buying this piece of junk.        Negative    0.343019\n",
      "               Mixed feelings - great price but questionable quality.        Negative    0.604844\n",
      "         Honestly expected nothing and still managed to be impressed!        Positive    0.339876\n",
      "             Would have been perfect if not for that one major issue.        Positive    0.319427\n",
      "         I'm not sure if I like it or not, very confusing experience.        Negative    0.330352\n",
      "                   Started great but ended up being a waste of money.        Negative    0.312833\n",
      "         The worst part? It actually works but I still hate using it.        Negative    0.377148\n",
      "              Surprisingly decent for the price, can't complain much.        Negative    0.282313\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_texts = [\n",
    "    \"I thought it would be terrible but it exceeded my expectations!\",\n",
    "    \"The product isn't bad but the customer service ruined everything.\",\n",
    "    \"Not the best, not the worst, just okay I guess.\",\n",
    "    \"I wanted to love it so badly but it let me down completely.\",\n",
    "    \"Despite the flaws, I'm surprisingly happy with my purchase.\",\n",
    "    \"The reviews said it was amazing but I found it utterly disappointing.\",\n",
    "    \"It's fine if you have low expectations, otherwise you'll hate it.\",\n",
    "    \"I can't believe how much I regret buying this piece of junk.\",\n",
    "    \"Mixed feelings - great price but questionable quality.\",\n",
    "    \"Honestly expected nothing and still managed to be impressed!\",\n",
    "    \"Would have been perfect if not for that one major issue.\",\n",
    "    \"I'm not sure if I like it or not, very confusing experience.\",\n",
    "    \"Started great but ended up being a waste of money.\",\n",
    "    \"The worst part? It actually works but I still hate using it.\",\n",
    "    \"Surprisingly decent for the price, can't complain much.\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_inputs = tokenizer(test_texts, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "test_inputs = {k: v.to(device) for k, v in test_inputs.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Text\": test_texts,\n",
    "    \"Predicted_Label\": [id2label[pred.item()] for pred in predictions],\n",
    "    \"Confidence\": torch.softmax(outputs.logits, dim=-1).max(dim=-1).values.cpu().numpy()\n",
    "})\n",
    "\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T20:38:19.680235Z",
     "iopub.status.busy": "2025-11-10T20:38:19.680039Z",
     "iopub.status.idle": "2025-11-10T20:38:41.581537Z",
     "shell.execute_reply": "2025-11-10T20:38:41.580590Z",
     "shell.execute_reply.started": "2025-11-10T20:38:19.680220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/bert_sentiment_model.zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "shutil.make_archive('bert_sentiment_model', 'zip', './bert_sentiment/final')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3471819,
     "sourceId": 6066255,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8595896,
     "sourceId": 13589916,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
