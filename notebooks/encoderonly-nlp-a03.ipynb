{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6066255,"sourceType":"datasetVersion","datasetId":3471819},{"sourceId":13586885,"sourceType":"datasetVersion","datasetId":8595896}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up enviorment","metadata":{}},{"cell_type":"code","source":"# !pip install -q transformers datasets accelerate evaluate scikit-learn torch\n# !pip install -U transformers huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.171293Z","iopub.execute_input":"2025-11-02T12:35:55.171608Z","iopub.status.idle":"2025-11-02T12:35:55.175541Z","shell.execute_reply.started":"2025-11-02T12:35:55.171588Z","shell.execute_reply":"2025-11-02T12:35:55.174618Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.176801Z","iopub.execute_input":"2025-11-02T12:35:55.177032Z","iopub.status.idle":"2025-11-02T12:35:55.190922Z","shell.execute_reply.started":"2025-11-02T12:35:55.177014Z","shell.execute_reply":"2025-11-02T12:35:55.190132Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import inspect\nfrom transformers import TrainingArguments\nprint(inspect.signature(TrainingArguments))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.191978Z","iopub.execute_input":"2025-11-02T12:35:55.192311Z","iopub.status.idle":"2025-11-02T12:35:55.206366Z","shell.execute_reply.started":"2025-11-02T12:35:55.192290Z","shell.execute_reply":"2025-11-02T12:35:55.205687Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"(output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: Optional[float] = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str, NoneType] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: Optional[bool] = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, use_ipex: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: Optional[bool] = True, label_names: Optional[list[str]] = None, load_best_model_at_end: Optional[bool] = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = '', fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: Optional[str] = 'length', report_to: Union[NoneType, str, list[str]] = None, ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: Optional[bool] = False, include_num_input_tokens_seen: Optional[bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: Optional[bool] = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: Optional[bool] = False, average_tokens_across_devices: Optional[bool] = False) -> None\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os, random, numpy as np, pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.207125Z","iopub.execute_input":"2025-11-02T12:35:55.207373Z","iopub.status.idle":"2025-11-02T12:35:55.219729Z","shell.execute_reply.started":"2025-11-02T12:35:55.207350Z","shell.execute_reply":"2025-11-02T12:35:55.219001Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Import file and analyze it ","metadata":{}},{"cell_type":"code","source":"Seed=42\nrandom.seed(Seed)\nnp.random.seed(Seed)\nos.environ[\"PYTHONHASHSHEED\"]=str(Seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.221332Z","iopub.execute_input":"2025-11-02T12:35:55.221542Z","iopub.status.idle":"2025-11-02T12:35:55.236705Z","shell.execute_reply.started":"2025-11-02T12:35:55.221526Z","shell.execute_reply":"2025-11-02T12:35:55.235959Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sensitive-analysis/sentiment-analysis.csv', sep=\",\", engine=\"python\")\nprint(\"Columns:\", df.columns.tolist())\nprint(df.head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.237501Z","iopub.execute_input":"2025-11-02T12:35:55.237729Z","iopub.status.idle":"2025-11-02T12:35:55.257846Z","shell.execute_reply.started":"2025-11-02T12:35:55.237713Z","shell.execute_reply":"2025-11-02T12:35:55.257098Z"}},"outputs":[{"name":"stdout","text":"Columns: ['Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score']\n  Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score\n0  I love this product!, Positive, Twitter, 2023-...                     \n1  The service was terrible., Negative, Yelp Revi...                     \n2  This movie is amazing!, Positive, IMDb, 2023-0...                     \n3  I'm so disappointed with their customer suppor...                     \n4  Just had the best meal of my life!, Positive, ...                     \n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Preprocessing\n### we may observe our sentiments are positive or negative convert them to digit 0 or 1","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.strip()\ntext_col = 'Text'\nlabel_col = 'Sentiment'\n\nunique = sorted(df[label_col].unique())\nlabel2id = {lab: i for i, lab in enumerate(unique)}\nid2label = {i: lab for lab, i in label2id.items()}\n\ndf[\"label\"] = df[label_col].map(label2id)\n\nprint(\"Label map:\", label2id)\nprint(df[[text_col, label_col, \"label\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:36:36.564143Z","iopub.execute_input":"2025-11-02T12:36:36.564836Z","iopub.status.idle":"2025-11-02T12:36:36.619071Z","shell.execute_reply.started":"2025-11-02T12:36:36.564816Z","shell.execute_reply":"2025-11-02T12:36:36.618197Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Sentiment'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3096963952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlabel2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mid2label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel2id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Sentiment'"],"ename":"KeyError","evalue":"'Sentiment'","output_type":"error"}],"execution_count":15},{"cell_type":"markdown","source":"# Lets convert our data set into Hugging face format \n### for testing we are using small dataset","metadata":{}},{"cell_type":"code","source":"data=Dataset.from_pandas(df[[text_col,\"label\"]])\ndata_split=data.train_test_split(test_size=0.2,seed=Seed)\ndataset=DatasetDict({\"train\":data_split[\"train\"],\"validation\":data_split[\"test\"]})\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.323662Z","iopub.status.idle":"2025-11-02T12:35:55.323965Z","shell.execute_reply.started":"2025-11-02T12:35:55.323809Z","shell.execute_reply":"2025-11-02T12:35:55.323823Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing our BERT Model","metadata":{}},{"cell_type":"code","source":"model_base = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_base)\n\ndef preprocess(batch):\n    return tokenizer(batch[text_col], padding=\"max_length\", max_length=128, truncation=True)\n\ndataset = dataset.map(preprocess, batched=True)\ndataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.324991Z","iopub.status.idle":"2025-11-02T12:35:55.325344Z","shell.execute_reply.started":"2025-11-02T12:35:55.325181Z","shell.execute_reply":"2025-11-02T12:35:55.325195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_labels=len(label2id)\nmodel=AutoModelForSequenceClassification.from_pretrained(model_base,num_labels=num_labels,id2label=id2label,label2id=label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.326256Z","iopub.status.idle":"2025-11-02T12:35:55.326562Z","shell.execute_reply.started":"2025-11-02T12:35:55.326407Z","shell.execute_reply":"2025-11-02T12:35:55.326419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaulation metrices\nfrom inspect import signature\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.327365Z","iopub.status.idle":"2025-11-02T12:35:55.327658Z","shell.execute_reply.started":"2025-11-02T12:35:55.327509Z","shell.execute_reply":"2025-11-02T12:35:55.327522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hugging face default parameters for model training \ntraining_args = TrainingArguments(\n    output_dir=\"./bert_sentiment\",\n    learning_rate=2e-5,\n    eval_strategy=\"epoch\", \n    save_strategy=\"epoch\",\n    \n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\",\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.328759Z","iopub.status.idle":"2025-11-02T12:35:55.329077Z","shell.execute_reply.started":"2025-11-02T12:35:55.328907Z","shell.execute_reply":"2025-11-02T12:35:55.328920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.329687Z","iopub.status.idle":"2025-11-02T12:35:55.329986Z","shell.execute_reply.started":"2025-11-02T12:35:55.329823Z","shell.execute_reply":"2025-11-02T12:35:55.329837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.331152Z","iopub.status.idle":"2025-11-02T12:35:55.331525Z","shell.execute_reply.started":"2025-11-02T12:35:55.331367Z","shell.execute_reply":"2025-11-02T12:35:55.331381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_out = trainer.predict(dataset[\"validation\"])\npreds = np.argmax(pred_out.predictions, axis=-1)\nlabels = pred_out.label_ids\n\nprint(\"Accuracy:\", accuracy_score(labels, preds))\nprint(\"Macro F1:\", f1_score(labels, preds, average=\"macro\"))\nprint(\"\\nClassification Report:\\n\", classification_report(labels, preds, target_names=[str(x) for x in unique]))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(labels, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.333087Z","iopub.status.idle":"2025-11-02T12:35:55.334048Z","shell.execute_reply.started":"2025-11-02T12:35:55.333874Z","shell.execute_reply":"2025-11-02T12:35:55.333890Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(\"./bert_sentiment/final\")\ntokenizer.save_pretrained(\"./bert_sentiment/final\")\nprint(\"Saved to ./bert_sentiment/final\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.334503Z","iopub.status.idle":"2025-11-02T12:35:55.334906Z","shell.execute_reply.started":"2025-11-02T12:35:55.334742Z","shell.execute_reply":"2025-11-02T12:35:55.334756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ntest_texts = [\n    \"I thought it would be terrible but it exceeded my expectations!\",\n    \"The product isn't bad but the customer service ruined everything.\",\n    \"Not the best, not the worst, just okay I guess.\",\n    \"I wanted to love it so badly but it let me down completely.\",\n    \"Despite the flaws, I'm surprisingly happy with my purchase.\",\n    \"The reviews said it was amazing but I found it utterly disappointing.\",\n    \"It's fine if you have low expectations, otherwise you'll hate it.\",\n    \"I can't believe how much I regret buying this piece of junk.\",\n    \"Mixed feelings - great price but questionable quality.\",\n    \"Honestly expected nothing and still managed to be impressed!\",\n    \"Would have been perfect if not for that one major issue.\",\n    \"I'm not sure if I like it or not, very confusing experience.\",\n    \"Started great but ended up being a waste of money.\",\n    \"The worst part? It actually works but I still hate using it.\",\n    \"Surprisingly decent for the price, can't complain much.\"\n]\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntest_inputs = tokenizer(test_texts, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\ntest_inputs = {k: v.to(device) for k, v in test_inputs.items()}\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**test_inputs)\n    predictions = torch.argmax(outputs.logits, dim=-1)\n\nresults = pd.DataFrame({\n    \"Text\": test_texts,\n    \"Predicted_Label\": [id2label[pred.item()] for pred in predictions],\n    \"Confidence\": torch.softmax(outputs.logits, dim=-1).max(dim=-1).values.cpu().numpy()\n})\n\nprint(results.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.335848Z","iopub.status.idle":"2025-11-02T12:35:55.336180Z","shell.execute_reply.started":"2025-11-02T12:35:55.336007Z","shell.execute_reply":"2025-11-02T12:35:55.336021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import files\nimport shutil\nshutil.make_archive('bert_sentiment_model', 'zip', './bert_sentiment/final')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:35:55.337662Z","iopub.status.idle":"2025-11-02T12:35:55.337976Z","shell.execute_reply.started":"2025-11-02T12:35:55.337814Z","shell.execute_reply":"2025-11-02T12:35:55.337826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}